## Dubbing and Talking-Head Animation

**OneGT: One-Shot Geometry-Texture Neural Rendering for Head Avatars.**<br>
*Jinshu Chen, Bingchuan Li, Fan Zhang, Songtao Zhao, Qian He.*<br>
ICCV 2025. [[PDF](https://iccv.thecvf.com/media/PosterPDFs/ICCV%202025/2168.png?t=1757905957.5566292)]

**Generalizable One-shot Neural Head Avatar.**<br>
*Xueting Li, Shalini De Mello, Sifei Liu, Koki Nagano, Umar Iqbal, Jan Kautz.*<br>
NeurIPS 2023. [[PDF](https://arxiv.org/abs/2306.08768)]

**Free-HeadGAN: Neural Talking Head Synthesis With Explicit Gaze Control.**<br>
*Michail Christos Doukas, Evangelos Ververas, Viktoriia Sharmanska, Stefanos Zafeiriou.*<br>
TPAMI 2023. [[PDF](https://arxiv.org/pdf/2208.02210.pdf)]

**SPACE: Speech-driven Portrait Animation with Controllable Expression.**<br>
*Siddharth Gururani, Arun Mallya, Ting-Chun Wang, Rafael Valle, Ming-Yu Liu.*<br>
ICCV 2023. [[PDF](https://arxiv.org/abs/2211.09809)] [[Project](https://deepimagination.cc/SPACEx/)]

**Instant Volumetric Head Avatars.**<br>
*Wojciech Zielonka, Timo Bolkart, Justus Thies.*<br>
CVPR 2023. [[PDF](https://arxiv.org/abs/2211.12499)] [[Project](https://zielon.github.io/insta/)] [[Video](https://youtu.be/HOgaeWTih7Q)]

**LiP-Flow: Learning Inference-time Priors for Codec Avatars Via Normalizing Flows in Latent Space.**<br>
*Emre Aksan, Shugao Ma, Akin Caliskan, Stanislav Pidhorskyi, Alexander Richard, Shih-En Wei, Jason Saragih, Otmar Hilliges.*<br>
ECCV 2022. [[PDF](https://arxiv.org/abs/2203.07881)]

**Talking Head from Speech Audio using a Pre-trained Image Generator.**<br>
*Mohammed M. Alghamdi, He Wang, Andrew J. Bulpitt, David C. Hogg.*<br>
ACM MM 2022. [[PDF](https://arxiv.org/abs/2209.04252)] [[Code](https://mohammedalghamdi.github.io/talking-heads-acm-mm)]

**Speech Driven Tongue Animation.**<br>
*Salvador Medina, Denis Tome, Carsten Stoll, Mark Tiede, Kevin Munhall, Alexander G. Hauptmann, Iain Matthews.*<br>
CVPR 2022. [[PDF](https://openaccess.thecvf.com/content/CVPR2022/html/Medina_Speech_Driven_Tongue_Animation_CVPR_2022_paper.html)]

**Talking Face Generation With Multilingual TTS.**<br>
*Hyoung-Kyu Song, Sang Hoon Woo, Junhyeok Lee, Seungmin Yang, Hyunjae Cho, Youseong Lee, Dongho Choi, Kang-wook Kim.*<br>
CVPR 2022. [[PDF](http://arxiv.org/abs/2205.06421)]

**Thin-Plate Spline Motion Model for Image Animation.**<br>
*Jian Zhao, Hui Zhang.*<br>
CVPR 2022. [[PDF](https://arxiv.org/abs/2203.14367)]

**Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation.**<br>
*Xian Liu, Qianyi Wu, Hang Zhou, Yinghao Xu, Rui Qian, Xinyi Lin, Xiaowei Zhou, Wayne Wu, Bo Dai, Bolei Zhou.*<br>
CVPR 2022. [[PDF](https://arxiv.org/abs/2203.13161)]

**Depth-Aware Generative Adversarial Network for Talking Head Video Generation.**<br>
*Fa-Ting Hong, Longhao Zhang, Li Shen, Dan Xu*<br>
CVPR 2022. [[PDF](https://arxiv.org/abs/2203.06605)] [[Code](https://github.com/harlanhong/CVPR2022-DaGAN)]

**FaceFormer: Speech-Driven 3D Facial Animation with Transformers.**<br>
*Yingruo Fan, Zhaojiang Lin, Jun Saito, Wenping Wang, Taku Komura.*<br>
CVPR 2022. [[PDF](https://arxiv.org/abs/2112.05329)]

**Everybody's Talkin': Let Me Talk as You Want.**<br>
*Linsen Song, [Wayne Wu](http://wywu.github.io/), Chen Qian, [Ran He](https://scholar.google.com/citations?user=ayrg9AUAAAAJ&hl=en), Chen Change Loy.*<br>
TIFS 2022. [[PDF](https://arxiv.org/abs/2001.05201)] [[Project](https://wywu.github.io/projects/EBT/EBT.html)]

**SAFA: Structure Aware Face Animation.**<br>
*Qiulin Wang, Lu Zhang, Bo Li.*<br>
3DV 2021. [[PDF](https://arxiv.org/abs/2111.04928)] [[Code](https://github.com/Qiulin-W/SAFA)]

**One-shot Talking Face Generation from Single-speaker Audio-Visual Correlation Learning.**<br>
*Suzhen Wang, Lincheng Li, Yu Ding, Xin Yu.*<br>
AAAI 2022. [[PDF](https://arxiv.org/abs/2112.02749)]

**Talking Head Generation with Audio and Speech Related Facial Action Units.**<br>
*Sen Chen, Zhilei Liu, Jiaxing Liu, Zhengxiang Yan, Longbiao Wang.*<br>
BMVC 2021. [[PDF](https://arxiv.org/abs/2110.09951)]

**Live Speech Portraits: Real-Time Photorealistic Talking-Head Animation.**<br>
*Yuanxun Lu, Jinxiang Chai, Xun Cao.*<br>
SIGGRAPH Asia 2021. [[PDF](https://arxiv.org/abs/2109.10595)]

**DECA: Learning an Animatable Detailed 3D Face Model from In-The-Wild Images.**<br>
*Yao Feng, Haiwen Feng, Michael J. Black, Timo Bolkart.*<br>
SIGGRAPH 2021. [[PDF](https://arxiv.org/abs/2012.04012)] [[Code](https://github.com/YadiraF/DECA)]

**Towards Realistic Visual Dubbing with Heterogeneous Sources.**<br>
*Tianyi Xie, Liucheng Liao, Cheng Bi, Benlai Tang, Xiang Yin, Jianfei Yang, Mingjie Wang, Jiali Yao, Yang Zhang, Zejun Ma.*<br>
ACM MM 2021. [[PDF](https://arxiv.org/abs/2201.06260)]

**Learned Spatial Representations for Few-Shot Talking-Head Synthesis.**<br>
*Moustafa Meshry, Saksham Suri, Larry S. Davis, Abhinav Shrivastava.*<br>
ICCV 2021. [[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Meshry_Learned_Spatial_Representations_for_Few-Shot_Talking-Head_Synthesis_ICCV_2021_paper.html)]

**The Right To Talk: An Audio-Visual Transformer Approach.**<br>
*Thanh-Dat Truong, Chi Nhan Duong, The De Vu, Hoang Anh Pham, Bhiksha Raj, Ngan Le, Khoa Luu.*<br>
ICCV 2021. [[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Truong_The_Right_To_Talk_An_Audio-Visual_Transformer_Approach_ICCV_2021_paper.html)]

**Speech Drives Templates: Co-Speech Gesture Synthesis With Learned Templates.**<br>
*Shenhan Qian, Zhi Tu, Yihao Zhi, Wen Liu, Shenghua Gao.*<br>
ICCV 2021. [[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Qian_Speech_Drives_Templates_Co-Speech_Gesture_Synthesis_With_Learned_Templates_ICCV_2021_paper.html)]

**AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis.**<br>
*[Yudong Guo](https://yudongguo.github.io/), [Keyu Chen](http://kychern.github.io/), Sen Liang, [Yongjin Liu](https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm), [Hujun Bao](http://www.cad.zju.edu.cn/bao/), [Juyong Zhang](http://staff.ustc.edu.cn/~juyong/).*<br>
ICCV 2021. [[PDF](https://arxiv.org/abs/2103.11078)] [[Project](https://yudongguo.github.io/ADNeRF/)] [[Video](https://www.youtube.com/watch?v=TQO2EBYXLyU)]

**FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning.**<br>
*Chenxu Zhang, Yifan Zhao, Yifei Huang, Ming Zeng, Saifeng Ni, Madhukar Budagavi, Xiaohu Guo.*<br>
ICCV 2021. [[PDF](https://arxiv.org/abs/2108.07938)]

**MeshTalk: 3D Face Animation from Speech using Cross-Modality Disentanglement.**<br>
*[Alexander Richard](https://alexanderrichard.github.io/), Michael Zollhoefer, Yandong Wen, Fernando de la Torre, Yaser Sheikh.*<br>
ICCV 2021. [[PDF](https://arxiv.org/abs/2104.08223)] [[Video](https://research.fb.com/wp-content/uploads/2021/04/mesh_talk.mp4)]

**HeadGAN: Video-and-Audio-Driven Talking Head Synthesis.**<br>
*Michail Christos Doukas, Stefanos Zafeiriou, Viktoriia Sharmanska.*<br>
ICCV 2021. [[PDF](https://arxiv.org/abs/2012.08261)]

**Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion.**<br>
*Suzhen Wang, Lincheng Li, Yu Ding, Changjie Fan, Xin Yu.*<br>
IJCAI 2021. [[PDF](https://arxiv.org/abs/2107.09293)]

**Imitating Arbitrary Talking Style for Realistic Audio-Driven Talking Face Synthesis.**<br>
*Haozhe Wu, Jia Jia, Haoyu Wang, Yishun Dou, Chao Duan, Qingshan Deng.*<br>
ACM MM 2021. [[PDF](https://hcsi.cs.tsinghua.edu.cn/Paper/Paper21/MM21-WUHAOZHE.pdf)] [[Code](https://github.com/wuhaozhe/style_avatar)]

**LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization.**<br>
*Avisek Lahiri, Vivek Kwatra, Christian Frueh, John Lewis, Chris Bregler.*<br>
CVPR 2021. [[PDF](https://arxiv.org/abs/2106.04185)]

**Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation.**<br> 
*[Hang Zhou](https://hangz-nju-cuhk.github.io/), Yasheng Sun, [Wayne Wu](https://wywu.github.io/), Chen Change Loy, Xiaogang Wang, Ziwei Liu.*<br>
CVPR 2021. [[PDF](https://arxiv.org/abs/2104.11116)] [[Project](https://hangz-nju-cuhk.github.io/)] [[Code](https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS)]

**Everything's Talkin': Pareidolia Face Reenactment.**<br>
*Linsen Song, [Wayne Wu](https://wywu.github.io), Chaoyou Fu, Chen Qian, Chen Change Loy, Ran He.*<br>
CVPR 2021. [[PDF](https://arxiv.org/abs/2104.03061)] [[Project](https://wywu.github.io/projects/ETT/ETT.html)] [[Code](https://github.com/Linsen13/EverythingTalking)]

**One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing.**<br>
*[Ting-Chun Wang](https://tcwang0509.github.io/), [Arun Mallya](https://arunmallya.github.io/), [Ming-Yu Liu](http://mingyuliu.net/).*<br>
CVPR 2021 (oral). [[PDF](https://arxiv.org/abs/2011.15126)] [[Project](https://nvlabs.github.io/face-vid2vid)]

**Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation.**<br>
*Lincheng Li, Suzhen Wang, Zhimeng Zhang, Yu Ding, Yixing Zheng, Xin Yu, Changjie Fan.*<br>
AAAI 2021. [[PDF](https://arxiv.org/pdf/2104.07995.pdf)]

**FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis.**<br>
*Kuangxiao Gu, Yuqian Zhou, Thomas Huang.*<br>
AAAI 2020. [[PDF](https://arxiv.org/abs/1911.09224)] [[Code](https://github.com/kgu3/FLNet_AAAI2020)]

**MEAD: A Large-scale Audio-visual Dataset for Emotional Talking Face Generation.**<br>
*Kaisiyuan Wang, [Qianyi Wu](https://wuqianyi.top/), Linsen Song, [Zhuoqian Yang](https://yzhq97.github.io/), Wayne Wu, Chen Qian, Ran He, Yu Qiao, Chen Change Loy.*<br>
ECCV 2020. [[PDF](https://wywu.github.io/)] [[Project](https://wywu.github.io/projects/MEAD/MEAD.html)] [[Code](https://github.com/uniBruce/Mead)] 

**MakeItTalk: Speaker-Aware Talking-Head Animation.**<br>
*Yang Zhou, Xintong Han, Eli Shechtman, Jose Echevarria, Evangelos Kalogerakis, Dingzeyu Li.*<br>
TOG 2020. [[PDF](https://arxiv.org/abs/2004.12992)] [[Code](https://github.com/adobe-research/MakeItTalk)]

**Text-based Editing of Talking-head Video.**<br>
*Ohad Fried, Ayush Tewari, Michael Zollhöfer, Adam Finkelstein, Eli Shechtman, Dan B Goldman Kyle Genova, Zeyu Jin, Christian Theobalt,  Maneesh Agrawala.*<br>
TOG 2019. [[PDF](https://www.ohadf.com/projects/text-based-editing/data/text-based-editing.pdf)] [[Project](https://www.ohadf.com/projects/text-based-editing/)]

**ATVGnet: Hierarchical Cross-Modal Talking Face Generationwith Dynamic Pixel-Wise Loss.**<br>
*[Lele Chen](http://www.cs.rochester.edu/u/lchen63/), [Ross K. Maddox](https://www.urmc.rochester.edu/labs/maddox.aspx), [Zhiyao Duan](http://www2.ece.rochester.edu/~zduan/), [Chenliang Xu](https://www.cs.rochester.edu/~cxu22/).*<br>
CVPR 2019. [[PDF](https://arxiv.org/abs/1905.03820)] [[Code](https://github.com/lelechen63/ATVGnet)]

**Talking Face Generation by Adversarially Disentangled Audio-Visual Representation.**<br>
*Hang Zhou, Yu Liu, Ziwei Liu, Ping Luo, Xiaogang Wang.*<br>
AAAI 2019. [[PDF](https://arxiv.org/abs/1807.07860)] [[Code](https://github.com/Hangz-nju-cuhk/Talking-Face-Generation-DAVS)] [[Project](https://liuziwei7.github.io/projects/TalkingFace.html)]

**VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time.**<br>
*Sicheng Xu, Guojun Chen, Yu-Xiao Guo, Jiaolong Yang, Chong Li, Zhenyu Zang, Yizhong Zhang, Xin Tong, Baining Guo.*<br>
arxiv 2024. [[PDF](https://arxiv.org/abs/2404.10667)] [[Project](https://www.microsoft.com/en-us/research/project/vasa-1/)]
